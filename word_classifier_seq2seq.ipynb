{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "import time\n",
    "import math\n",
    "import unidecode\n",
    "\n",
    "sys.path.append('src')\n",
    "from ocr.datahelpers import load_words_data, corresponding_shuffle, char2idx\n",
    "from ocr.helpers import img_extend\n",
    "from ocr.mlhelpers import TrainingPlot\n",
    "from ocr.tfhelpers import create_cell\n",
    "from ocr.imgtransform import coordinates_remap\n",
    "\n",
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = (9.0, 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading words...\n",
      " |████████████████████████████████████████| 100.0% \n",
      "-> Number of words: 5069\n"
     ]
    }
   ],
   "source": [
    "images, labels = load_words_data(\n",
    "    ['data/processed/breta/words_gaplines/'], load_gaplines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_size = 82 if LANG =='cz' else 52\n",
    "\n",
    "PAD = 0   # Padding\n",
    "EOS = 1   # End of seq\n",
    "\n",
    "num_new_images = 2                \n",
    "fac_alpha = 2.0                    \n",
    "fac_sigma = 0.08\n",
    "\n",
    "num_buckets = 5\n",
    "slider_size = (60, 2)\n",
    "N_INPUT = 60*2                     \n",
    "vocab_size = char_size + 2        \n",
    "input_embedding_size = vocab_size   \n",
    "\n",
    "\n",
    "encoder_layers = 2\n",
    "decoder_layers = 2*encoder_layers  # 2* is due to the bidirectional encoder\n",
    "encoder_residual_layers = 1        # HAVE TO be smaller than encoder_layers\n",
    "decoder_residual_layers = 2*encoder_residual_layers\n",
    "encoder_units = 256\n",
    "decoder_units = encoder_units\n",
    "\n",
    "add_output_length = 4 # 4\n",
    "\n",
    "learning_rate = 1e-4               # 1e-4\n",
    "max_gradient_norm = 5.0            # For gradient clipping\n",
    "dropout = 0.4\n",
    "train_per = 0.8                    # Percentage of training data\n",
    "\n",
    "TRAIN_STEPS = 100000               # Number of training steps!\n",
    "TEST_ITER = 150\n",
    "LOSS_ITER = 50\n",
    "SAVE_ITER = 2000\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 2000                       # Number of batches in epoch - not accurate\n",
    "\n",
    "save_location = 'models/word-clas/' + LANG + '/WordClassifier2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 4055\n",
      "Testing images: 1014\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data for later splitting\n",
    "images, labels = corresponding_shuffle([images, labels])\n",
    "\n",
    "labels_idx = np.empty(len(labels), dtype=object)\n",
    "for i, label in enumerate(labels):\n",
    "    labels_idx[i] = [char2idx(c, True) for c in label]\n",
    "    \n",
    "# Split data on train and test dataset\n",
    "div = int(train_per * len(images))\n",
    "\n",
    "trainImages = images[0:div]\n",
    "testImages = images[div:]\n",
    "\n",
    "trainLabels_idx = labels_idx[0:div]\n",
    "testLabels_idx = labels_idx[div:]\n",
    "\n",
    "print(\"Training images:\", div)\n",
    "print(\"Testing images:\", len(images) - div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset extending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed train images 12165\n"
     ]
    }
   ],
   "source": [
    "# Dont mix train and test images\n",
    "trainImagesFinal = np.empty(len(trainImages) * (num_new_images+1), dtype=object)\n",
    "trainLabelsFinal_idx = np.empty(len(trainImages)*(num_new_images+1), dtype=object)\n",
    "for idx, img in enumerate(trainImages):\n",
    "    trainImagesFinal[idx*(num_new_images+1)] = img\n",
    "    trainLabelsFinal_idx[idx*(num_new_images+1)] = trainLabels_idx[idx]\n",
    "    for i in range(num_new_images):\n",
    "        trainImagesFinal[idx*(num_new_images+1) + (i+1)] = coordinates_remap(img, fac_alpha, fac_sigma)\n",
    "        trainLabelsFinal_idx[idx*(num_new_images+1) + (i+1)] = trainLabels_idx[idx]\n",
    "        \n",
    "print(\"Transformed train images\", len(trainImagesFinal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BucketDataIterator():\n",
    "    \"\"\" Iterator for feeding seq2seq model during training \"\"\"\n",
    "    def __init__(self,\n",
    "                 images,\n",
    "                 targets,\n",
    "                 num_buckets=5,\n",
    "                 slider=(60, 30),\n",
    "                 train=True):\n",
    "        \n",
    "        self.train = train\n",
    "        \n",
    "        # First PADDING of images to slider size ( -(a // b) ==  ceil(a/b))\n",
    "        self.slider = slider\n",
    "        for i in range(len(images)):\n",
    "            images[i] = img_extend(\n",
    "                images[i],\n",
    "                (images[i].shape[0], -(-images[i].shape[1] // slider[1]) * slider[1]))\n",
    "        in_length = [image.shape[1]//slider[1] for image in images]\n",
    "        \n",
    "        # Split images to sequence of vectors\n",
    "        imgseq = np.empty(len(images), dtype=object)\n",
    "        for i, img in enumerate(images):\n",
    "            imgseq[i] = [img[:, loc * slider[1]: (loc+1) * slider[1]].flatten()\n",
    "                         for loc in range(in_length[i])]\n",
    "\n",
    "        # Create pandas dataFrame and sort it by images width (length) \n",
    "        self.dataFrame = pd.DataFrame({'in_length': in_length,\n",
    "                                       'out_length': [len(t) for t in targets],\n",
    "                                       'images': imgseq,\n",
    "                                       'targets': targets\n",
    "                                      }).sort_values('in_length').reset_index(drop=True)\n",
    "\n",
    "        bsize = int(len(images) / num_buckets)\n",
    "        self.num_buckets = num_buckets\n",
    "        \n",
    "        # Create buckets by slicing parts by indexes\n",
    "        self.buckets = []\n",
    "        for bucket in range(num_buckets-1):\n",
    "            self.buckets.append(self.dataFrame.iloc[bucket * bsize: (bucket+1) * bsize])\n",
    "        self.buckets.append(self.dataFrame.iloc[(num_buckets-1) * bsize:])        \n",
    "        \n",
    "        self.buckets_size = [len(bucket) for bucket in self.buckets]\n",
    "\n",
    "        # cursor[i] will be the cursor for the ith bucket\n",
    "        self.cursor = np.array([0] * num_buckets)\n",
    "        self.bucket_order = np.random.permutation(num_buckets)\n",
    "        self.bucket_cursor = 0\n",
    "        self.shuffle()\n",
    "        print(\"Iterator created.\")\n",
    "\n",
    "    def shuffle(self, idx=None):\n",
    "        \"\"\" Shuffle idx bucket or each bucket separately \"\"\"\n",
    "        for i in [idx] if idx is not None else range(self.num_buckets):\n",
    "            self.buckets[i] = self.buckets[i].sample(frac=1).reset_index(drop=True)\n",
    "            self.cursor[i] = 0\n",
    "\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"\n",
    "        Creates next training batch of size: batch_size\n",
    "        Retruns: image seq, letter seq,\n",
    "                 image seq lengths, letter seq lengths\n",
    "        \"\"\"\n",
    "        i_bucket = self.bucket_order[self.bucket_cursor]\n",
    "        # Increment cursor and shuffle in case of new round\n",
    "        self.bucket_cursor = (self.bucket_cursor + 1) % self.num_buckets\n",
    "        if self.bucket_cursor == 0:\n",
    "            self.bucket_order = np.random.permutation(self.num_buckets)\n",
    "            \n",
    "        if self.cursor[i_bucket] + batch_size > self.buckets_size[i_bucket]:\n",
    "            self.shuffle(i_bucket)\n",
    "\n",
    "        # Handle too big batch sizes\n",
    "        if (batch_size > self.buckets_size[i_bucket]):\n",
    "            batch_size = self.buckets_size[i_bucket]\n",
    "\n",
    "        res = self.buckets[i_bucket].iloc[self.cursor[i_bucket]:\n",
    "                                          self.cursor[i_bucket]+batch_size]\n",
    "        self.cursor[i_bucket] += batch_size\n",
    "\n",
    "        # PAD input sequence and output\n",
    "        # Pad sequences with <PAD> to same length\n",
    "        input_max = max(res['in_length'])\n",
    "        output_max = max(res['out_length'])\n",
    "        # In order to make it work at production\n",
    "        assert np.all(res['in_length'] + add_output_length >= res['out_length'])\n",
    "        \n",
    "        input_seq = np.zeros((batch_size, input_max, N_INPUT), dtype=np.float32)\n",
    "        for i, img in enumerate(res['images']):\n",
    "            input_seq[i][:res['in_length'].values[i]] = img\n",
    "        input_seq = input_seq.swapaxes(0, 1)\n",
    "        \n",
    "        # Need to pad according to the maximum length output sequence\n",
    "        targets = np.zeros([batch_size, output_max], dtype=np.int32)\n",
    "        for i, target in enumerate(targets):\n",
    "            target[:res['out_length'].values[i]] = res['targets'].values[i]\n",
    "        targets = targets.swapaxes(0, 1)\n",
    "        \n",
    "        return input_seq, targets, res['in_length'].values, res['out_length'].values\n",
    "    \n",
    "    def next_feed(self, size):\n",
    "        \"\"\" Create feed directly for model training \"\"\"\n",
    "        (encoder_inputs_,\n",
    "         decoder_targets_,\n",
    "         encoder_inputs_length_,\n",
    "         decoder_targets_length_) = self.next_batch(size)\n",
    "        return {\n",
    "            encoder_inputs: encoder_inputs_,\n",
    "            encoder_inputs_length: encoder_inputs_length_,\n",
    "            decoder_targets: decoder_targets_,\n",
    "            decoder_targets_length: decoder_targets_length_,\n",
    "            keep_prob: (1.0 - dropout) if self.train else 1.0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterator created.\n",
      "Iterator created.\n"
     ]
    }
   ],
   "source": [
    "# Create iterator for feeding RNN\n",
    "# Create only once, it modifies: labels_idx\n",
    "train_iterator = BucketDataIterator(trainImagesFinal,\n",
    "                                    trainLabelsFinal_idx,\n",
    "                                    num_buckets,\n",
    "                                    slider_size,\n",
    "                                    train=True)\n",
    "test_iterator = BucketDataIterator(testImages,\n",
    "                                   testLabels_idx,\n",
    "                                   num_buckets,\n",
    "                                   slider_size,\n",
    "                                   train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input placehodlers\n",
    "# N_INPUT -> size of vector representing one image in sequence\n",
    "# Encoder inputs shape (max_seq_length, batch_size, vec_size)\n",
    "encoder_inputs = tf.placeholder(shape=(None, None, N_INPUT),\n",
    "                                dtype=tf.float32,\n",
    "                                name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                       dtype=tf.int32,\n",
    "                                       name='encoder_inputs_length')\n",
    "# required for training, not required for testing and application\n",
    "decoder_targets = tf.placeholder(shape=(None, None),\n",
    "                                 dtype=tf.int32,\n",
    "                                 name='decoder_targets')\n",
    "decoder_targets_length = tf.placeholder(shape=(None,),\n",
    "                                        dtype=tf.int32,\n",
    "                                        name='decoder_targets_length')\n",
    "# Dropout value\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Train Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_size, batch_size = tf.unstack(tf.shape(decoder_targets))\n",
    "\n",
    "test_length = tf.floor_div(tf.reduce_max(encoder_inputs_length), 7) + add_output_length\n",
    "\n",
    "EOS_SLICE = tf.ones([1, batch_size], dtype=tf.int32) * EOS\n",
    "PAD_SLICE = tf.ones([1, batch_size], dtype=tf.int32) * PAD\n",
    "\n",
    "# Train inputs with EOS symbol at start of seq\n",
    "decoder_train_inputs = tf.concat([EOS_SLICE, decoder_targets], axis=0)\n",
    "decoder_train_length = decoder_targets_length + 1\n",
    "\n",
    "# train targets with EOS symbol at end of seq\n",
    "decoder_train_targets = tf.concat([decoder_targets, PAD_SLICE], axis=0)\n",
    "decoder_train_targets_seq_len, _ = tf.unstack(tf.shape(decoder_train_targets))\n",
    "decoder_train_targets_eos_mask = tf.one_hot(decoder_train_length - 1,\n",
    "                                            decoder_train_targets_seq_len,\n",
    "                                            on_value=EOS, off_value=PAD,\n",
    "                                            dtype=tf.int32)\n",
    "decoder_train_targets_eos_mask = tf.transpose(decoder_train_targets_eos_mask, [1, 0])\n",
    "\n",
    "# hacky way using one_hot to put EOS symbol at the end of target sequence\n",
    "decoder_train_targets = tf.add(decoder_train_targets,\n",
    "                               decoder_train_targets_eos_mask)\n",
    "\n",
    "# Pad test accuracy\n",
    "decoder_test_targets = tf.pad(\n",
    "    decoder_train_targets,\n",
    "    [[0, test_length - decoder_train_targets_seq_len], [0, 0]],\n",
    "    mode='CONSTANT')\n",
    "\n",
    "loss_weights = tf.sequence_mask(\n",
    "    decoder_train_length,\n",
    "    tf.reduce_max(decoder_train_length),\n",
    "    dtype=tf.float32)\n",
    "\n",
    "test_weights = tf.sequence_mask(\n",
    "    decoder_train_length,\n",
    "    test_length,\n",
    "    dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly initialized embedding matrix, for characters embedding in decoder\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size,\n",
    "                                            input_embedding_size],\n",
    "                                           -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "decoder_train_inputs_embedded = tf.nn.embedding_lookup(\n",
    "    embeddings, decoder_train_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_cell_fw = create_cell(encoder_units,\n",
    "                          encoder_layers,\n",
    "                          encoder_residual_layers,\n",
    "                          is_dropout=True,\n",
    "                          keep_prob=keep_prob)\n",
    "enc_cell_bw = create_cell(encoder_units,\n",
    "                          encoder_layers,\n",
    "                          encoder_residual_layers,\n",
    "                          is_dropout=True,\n",
    "                          keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help functions for standard layers\n",
    "def conv2d(x, W, name=None):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name=name)\n",
    "\n",
    "def max_pool_2x2(x, name=None):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "# 1. Layer - Convulation variables\n",
    "W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 1, 4],\n",
    "                          initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[4]), name='b_conv1')\n",
    "# 3. Layer - Convulation variables\n",
    "W_conv2 = tf.get_variable('W_conv2', shape=[5, 5, 4, 8],\n",
    "                          initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[8]), name='b_conv2')\n",
    "\n",
    "def CNN(x):\n",
    "    x = tf.image.per_image_standardization(x)\n",
    "    x_img = tf.reshape(x, [1, slider_size[0], slider_size[1], 1])\n",
    "    # 1. Layer - Convulation\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_img, W_conv1) + b_conv1, name='h_conv1')\n",
    "    # 2. Layer - Max Pool\n",
    "    h_pool1 = max_pool_2x2(h_conv1, name='h_pool1')\n",
    "    # 3. Layer - Convulation\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2, name='h_conv2')\n",
    "    # 4. Layer - Max Pool\n",
    "    return max_pool_2x2(h_conv2, name='h_pool2')\n",
    "\n",
    "# Input images CNN\n",
    "inputs = tf.map_fn(\n",
    "    lambda seq: tf.map_fn(\n",
    "        lambda img:\n",
    "            tf.reshape(\n",
    "                CNN(tf.reshape(img, [slider_size[0], slider_size[1], 1])), [-1]),\n",
    "        seq),\n",
    "    encoder_inputs,\n",
    "    dtype=tf.float32)\n",
    "\n",
    "# Bidirectional RNN, gibe fw and bw outputs separately\n",
    "enc_outputs, enc_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "    cell_fw = enc_cell_fw,\n",
    "    cell_bw = enc_cell_bw,\n",
    "    inputs = inputs,\n",
    "    sequence_length = encoder_inputs_length,\n",
    "    dtype = tf.float32,\n",
    "    time_major = True)\n",
    "\n",
    "encoder_outputs = tf.concat(enc_outputs, -1)\n",
    "\n",
    "if encoder_layers == 1:\n",
    "    encoder_state = enc_state\n",
    "else:\n",
    "    encoder_state = []\n",
    "    for layer_id in range(encoder_layers):\n",
    "        encoder_state.append(enc_state[0][layer_id])  # forward\n",
    "        encoder_state.append(enc_state[1][layer_id])  # backward\n",
    "    encoder_state = tuple(encoder_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_states: size [batch_size, max_time, num_units]\n",
    "attention_states = tf.transpose(encoder_outputs, [1, 0, 2])\n",
    "\n",
    "# Create an attention mechanism\n",
    "attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "    decoder_units, attention_states,\n",
    "    memory_sequence_length=encoder_inputs_length)\n",
    "\n",
    "\n",
    "decoder_cell = create_cell(decoder_units,\n",
    "                           decoder_layers,\n",
    "                           decoder_residual_layers,\n",
    "                           is_dropout=True,\n",
    "                           keep_prob=keep_prob)\n",
    "\n",
    "decoder_cell = seq2seq.AttentionWrapper(\n",
    "    decoder_cell, attention_mechanism,\n",
    "    attention_layer_size=decoder_units)\n",
    "\n",
    "decoder_initial_state = decoder_cell.zero_state(batch_size, tf.float32).clone(\n",
    "    cell_state=encoder_state)\n",
    "\n",
    "### TRAIN DECODER ###\n",
    "# Helper\n",
    "helper = seq2seq.TrainingHelper(\n",
    "    decoder_train_inputs_embedded, decoder_train_length, time_major=True)\n",
    "\n",
    "# Decoder\n",
    "projection_layer = layers_core.Dense(\n",
    "    vocab_size, use_bias=False)\n",
    "\n",
    "decoder = seq2seq.BasicDecoder(\n",
    "    decoder_cell, helper, decoder_initial_state,\n",
    "    output_layer=projection_layer)\n",
    "\n",
    "# Dynamic decoding\n",
    "# outputs.rnn_output   = plain output\n",
    "# outputs.sample_id = tf.argmax(outputs.rnn_output, axis=-1)\n",
    "outputs, final_context_state, _ = seq2seq.dynamic_decode(\n",
    "    decoder)\n",
    "\n",
    "logits_train = outputs.rnn_output\n",
    "prediction_train = outputs.sample_id\n",
    "\n",
    "\n",
    "### INFERENCE DECODER ###\n",
    "# Helper\n",
    "helper_infer = seq2seq.GreedyEmbeddingHelper(\n",
    "    embeddings,\n",
    "    tf.fill([batch_size], EOS), EOS)\n",
    "\n",
    "# Decoder\n",
    "decoder_infer = seq2seq.BasicDecoder(\n",
    "    decoder_cell, helper_infer, decoder_initial_state,\n",
    "    output_layer=projection_layer)\n",
    "\n",
    "# Dynamic decoding\n",
    "outputs_infer, final_context_state, final_seq_lengths = seq2seq.dynamic_decode(\n",
    "    decoder_infer,\n",
    "    impute_finished=True,\n",
    "#     maximum_iterations=tf.reduce_max(encoder_inputs_length) + add_output_length)\n",
    "    maximum_iterations=test_length)\n",
    "prediction_inference = tf.identity(outputs_infer.sample_id,\n",
    "                                   name='prediction_infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = tf.transpose(decoder_train_targets, [1, 0])\n",
    "test_targets = tf.transpose(decoder_test_targets, [1, 0])\n",
    "## Loss\n",
    "loss = seq2seq.sequence_loss(logits=logits_train,\n",
    "                             targets=targets,\n",
    "                             weights=loss_weights,\n",
    "                             name='loss')\n",
    "\n",
    "## Calculate and clip gradients\n",
    "params = tf.trainable_variables()\n",
    "gradients = tf.gradients(loss, params)\n",
    "clipped_gradients, _ = tf.clip_by_global_norm(\n",
    "    gradients, max_gradient_norm)\n",
    "\n",
    "### Optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_step = optimizer.apply_gradients(\n",
    "    zip(clipped_gradients, params),\n",
    "    name='train_step')\n",
    "\n",
    "\n",
    "### Evaluate model\n",
    "# Pad prediction to match lengths\n",
    "prediction_infer_padded = tf.pad(\n",
    "    prediction_inference,\n",
    "    [[0, 0], [0, test_length - tf.reduce_max(final_seq_lengths)]],\n",
    "    mode='CONSTANT')\n",
    "\n",
    "correct_prediction = tf.equal(prediction_infer_padded,\n",
    "                              test_targets)\n",
    "## Advanced accuracy only the elements of seq including EOS symbol\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_prediction, tf.float32)*test_weights)/tf.reduce_sum(test_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Creat plot for live stats ploting\n",
    "trainPlot = TrainingPlot(TRAIN_STEPS, TEST_ITER, LOSS_ITER)\n",
    "\n",
    "try:\n",
    "    for i_batch in range(TRAIN_STEPS):\n",
    "        fd = train_iterator.next_feed(BATCH_SIZE)\n",
    "        train_step.run(fd)\n",
    "        \n",
    "        if i_batch % LOSS_ITER == 0:\n",
    "            # Plotting loss\n",
    "            tmpLoss = loss.eval(fd)\n",
    "            trainPlot.updateCost(tmpLoss, i_batch // LOSS_ITER)\n",
    "    \n",
    "        if i_batch % TEST_ITER == 0:\n",
    "            # Plotting accuracy\n",
    "            fd_test = test_iterator.next_feed(BATCH_SIZE)\n",
    "            accTest = accuracy.eval(fd_test)\n",
    "            accTrain = accuracy.eval(fd)\n",
    "            trainPlot.updateAcc(accTest, accTrain, i_batch // TEST_ITER)\n",
    "\n",
    "        if i_batch % SAVE_ITER == 0:\n",
    "            saver.save(sess, save_location)\n",
    "        \n",
    "        if i_batch % EPOCH == 0:\n",
    "            fd_test = test_iterator.next_feed(BATCH_SIZE)\n",
    "            print('batch %r - loss: %r' % (i_batch, sess.run(loss, fd_test)))\n",
    "            predict_, target_ = sess.run([prediction_infer_padded, test_targets], fd_test)\n",
    "            for i, (inp, pred) in enumerate(zip(target_, predict_)):\n",
    "                print('    expected  > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 1:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    saver.save(sess, save_location)\n",
    "    print('Training interrupted, model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    expected  > [4 1 0 0 0 0 0 0 0]\n",
      "    predicted > [4 1 0 0 0 0 0 0 0]\n",
      "    expected  > [42 29 32 37 31 32 47 32  1]\n",
      "    predicted > [31 52 47 32 47  1  0  0  0]\n",
      "\n",
      "    expected  > [53 28 43 39 28 47 28  1  0  0  0  0  0  0  0]\n",
      "    predicted > [31 28 46 39 48 47 28  1  0  0  0  0  0  0  0]\n",
      "    expected  > [40 36 30  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [41 36 53  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "    expected  > [49 52 53 38 48 40 41 32  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "    predicted > [49 52 53 38 48 40 48  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "    expected  > [29 39 36 53 38 42  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "    predicted > [29 39 28 30 38 28  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "\n",
      "    expected  > [45 42 38  1  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [45 42 38  1  0  0  0  0  0  0  0  0  0]\n",
      "    expected  > [45 28 31  1  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [45 28 31  1  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "    expected  > [47 32 45 30 32 40  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "    predicted > [47 45 32 30 32 41  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "    expected  > [46 36 41 30 32  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "    predicted > [48 36 41 30 32  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    fd_test = test_iterator.next_feed(BATCH_SIZE)\n",
    "    predict_, target_ = sess.run([prediction_infer_padded, test_targets], fd_test)\n",
    "    for i, (inp, pred) in enumerate(zip(target_, predict_)):\n",
    "        print('    expected  > {}'.format(inp))\n",
    "        print('    predicted > {}'.format(pred))\n",
    "        if i >= 1:\n",
    "            break\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
